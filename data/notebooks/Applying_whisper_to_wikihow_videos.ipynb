{"cells":[{"cell_type":"markdown","metadata":{"id":"6H6bEJBuZuw8"},"source":["Getting videos from Wikihow dump"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AX_2aM7OJN5H"},"outputs":[{"ename":"OSError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-bb079e8d89c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/wikihow_dump_json/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/MyDrive/wikihow_dump_json/'"]}],"source":["import os\n","import pandas as pd\n","from datasets import load_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLekpZsBQPtD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_PyBsVyZZmD-"},"source":["Applying whisper to videos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZ49duD4QLlt"},"outputs":[],"source":["import whisper\n","import torch  # install steps: pytorch.org\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = whisper.load_model(\"large\").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bl1_oHOaQShd"},"outputs":[],"source":["from pathlib import Path\n","\n","# get list of MP3 audio files\n","paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n","print(len(paths))\n","print(paths[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-nRMa-1QXYc"},"outputs":[],"source":["data = []\n","for i, path in enumerate(tqdm(paths)):\n","    _id = path.split('/')[-1][:-4]\n","    # transcribe to get speech-to-text data\n","    result = model.transcribe(path)\n","    # add results to data list\n","    data.extend(result['segments'])\n","    break  # this is just part of the loop used as example"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNChg92WdqKbD5H11io8rOX","collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
